# Regret Matching for Discrete Colonel Blotto (S=5, K=3) — Hart Comparison

This repository contains a small, reproducible experiment suite for **two-player zero-sum discrete Colonel Blotto**
and a **sampled regret-matching** solver in the style of **Neller & Lanctot** (realised opponent action update).

The core goal is to:
1. Run regret matching self-play to obtain approximate equilibrium behaviour.
2. Measure convergence via **exploitability** and **value**.
3. Compare the learned strategy (after symmetrisation) to the **Hart target random-battlefield marginal** for the specific case \((S,K)=(5,3)\).

## References

- Sergiu Hart, *Discrete Colonel Blotto and General Lotto games*.
- Todd W. Neller and Marc Lanctot, *An Introduction to Counterfactual Regret Minimization*.

---

## Repo layout

At the top level:

- `game.py`  
  Builds the Blotto instance: enumerates pure allocations and constructs the payoff matrix `A`.

- `rm.py`  
  **Regret Matching (sampled)** self-play:
  - each time step uses mixed strategies from positive regrets,
  - samples realised actions,
  - updates regrets using the realised opponent move.

- `sym.py`  
  Symmetrisation utilities (treat battlefield labels as exchangeable by averaging over permutation classes).

- `metrics.py`  
  Evaluation utilities:
  - exploitability / Nash gap,
  - value of mixed strategies,
  - induced random-battlefield marginal,
  - TV distance,
  - Hart target marginal and Hart candidate strategy for \((S,K)=(5,3)\).

- `run.py`  
  Main experiment script. Produces figures and prints report-ready summary statistics.

- `visual.ipynb`  
  Interactive notebook for **UMAP 2D/3D visualisations**:
  - (1) normal strategies coloured by exploitability,
  - (2) symmetrised strategies coloured by exploitability,
  - (3) symmetrised strategies coloured by TV distance to Hart, with a **Hart candidate anchor**.

- `figures/`  
  Output directory (generated by `run.py` and/or the notebook).

- `Resources/`  
  Papers / notes used for the project (Hart, Neller–Lanctot, course notes, etc.).

- `requirement.txt`  
  Python dependencies.
---

## Setup

### 1) Create/activate a virtual environment (recommended)

```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
# .\venv\Scripts\activate # Windows PowerShell
```
### 2) Install dependencies
```bash
pip install -r requirement.txt
```

## Quickstart: run the main experiment

``bash
cd Code 
``

Default run (S=5, K=3, T=50000, 20 seeds for multi-seed diagnostics):

```bash
python run.py
```

Shorter run
```bash
python run.py --T 5000
```

Increase the number of seeds used for the multi-seed plots:
```bash
python run.py --T 5000 --nseeds 50
```

Use an explicit list of seeds: 
```bash
python run.py --T 5000 --seeds 0 1 2 3 4 5
```

Change main seed used for the single-run time-series curves:
```bash
python run.py --seed_main 7
```

Disable multi-seed diagnostics
```bash
python run.py --nseeds 0
```

Change the game size
```bash
python run.py --S 6 --K 4 --T 20000
```

## Outputs

All figures are saved into `Code/figures/` (or the directory passed via `--outdir`).

### Terminal summary

`run.py` prints a compact report:

Single-seed (final `T`):
- `exploitability(avg)`
- `exploitability(sym avg)`
- `value(avg strategies)`
- `value(sym avg strategies)`
- `TV(sym marginal, Hart)`

Across seeds (if multi-seed enabled):
- `exploitability(avg)`: median, IQR, range
- `exploitability(sym avg)`: median, IQR, range
- `TV-to-Hart (sym)`: median, IQR, range
- the best-TV seed and its TV and exploitability

Rescaled diagnostics (if multi-seed enabled):
- tail constants (median and IQR across seeds)
- rescaled values at the last evaluation time

### Figures saved

Single-seed figures:
1. `exploitability_vs_T.png`  
   Exploitability over time for averaged and symmetrised averaged strategies.

2. `value_vs_T.png`  
   Value `pbar_t^T A qbar_t` over time (also for symmetrised averages).

3. `tv_vs_T.png`  
   TV distance between learned symmetrised marginal and Hart target marginal over time.

4. `marginal_bar.png`  
   Side-by-side bar chart at final `T`: learned marginal (sym) vs Hart marginal.

Multi-seed figures (when enabled):
5. `tv_vs_exploit_scatter.png`  
   Scatter across seeds: exploitability of symmetrised averages vs TV distance to Hart.

6. `exploitability_rescaled_band.png`  
   Median and IQR band across seeds for rescaled exploitability diagnostics.

7. `marginal_bar_best_tv.png`  
   Bar chart for the seed with the smallest TV distance to Hart.
